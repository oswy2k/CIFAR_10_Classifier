{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e7e55c-9e0b-4c02-989f-28ab31cec255",
   "metadata": {},
   "source": [
    "## Cifar 10 Convolutional Neural Network Implementation\n",
    "\n",
    "This work contains the implementation of two kind of Neural Networks (AlexNet and a Custom model based in LeeNet and AlexNet), validating their capacity to classify the CIFAR10 dataset, a set of images that contains 10 different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a6bb33-7723-47fb-8914-945cf5522779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Imports #\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "# Torchvision Imports #\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# matplotlib imports #\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numpy imports #\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e635939-6437-43b3-bb1f-643368238cff",
   "metadata": {},
   "source": [
    "### Import Libraries needed for Google Drive mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6d8cf-f0c5-4df6-ae5d-94cf38010273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library installaation using pip for linux backend of colab#\n",
    "!pip install -U -q PyDrive\n",
    "\n",
    "# Import of Libraries from Drive using google collab api #\n",
    "import os\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "from google.colab import drive\n",
    "from google.colab import auth\n",
    "\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43674b9c-559b-4431-9cfb-3a81de1fbd08",
   "metadata": {},
   "source": [
    "### <u>Function used to Download data from Drive</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09707f4-5899-44aa-9d63-7b68e0161fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for downloading especific Data from the Drive folders #\n",
    "def download_Data(file_list, string_Discriminator):\n",
    "  # Check inside the folder if is already downlaoded #\n",
    "  downloaded = []\n",
    "\n",
    "  for path in os.scandir(\"/content/\"):\n",
    "    downloaded.append(path.name)\n",
    "\n",
    "  # Iterate through the files and download them to the data folder if not already downloaded, and are of the givne extension type#\n",
    "  for files in file_list:\n",
    "    if (string_Discriminator in files['title']) & (files['title'] not in downloaded):\n",
    "      print('title: %s, id: %s' % (files['title'], files['id']))\n",
    "      fname = os.path.join(local_download_path, files['title'])\n",
    "      print('downloading to {}'.format(fname))\n",
    "      f_ = drive.CreateFile({'id': files['id']})\n",
    "      f_.GetContentFile(fname)\n",
    "      downloaded.append(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce497b76-8083-4f16-919a-e1bab9b0aa56",
   "metadata": {},
   "source": [
    "### Import Files from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67123088-bd73-472e-9813-d9befa934cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "#Authentication and creation the PyDrive client.\n",
    "auth.authenticate_user()   #See if credentials are valid\n",
    "gauth = GoogleAuth()       #Start the authentication of the collab\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive.mount(\"/content/gdrive\")  #Mounts drive in the collab to save the important data\n",
    "drive = GoogleDrive(gauth) #Finishes the authentication\n",
    "\n",
    "#Choose a local directory inside the colab to import the data.\n",
    "local_download_path = os.path.expanduser('/content')\n",
    "\n",
    "# Try to make the directories in the colab #\n",
    "try:\n",
    "  os.makedirs(local_download_path)\n",
    "except: pass\n",
    "\n",
    "#Iterate through items using the query syntax for google drive\n",
    "#https://developers.google.com/drive/v2/web/search-parameters\n",
    "\n",
    "# Create a file list based on the query syntax searching in our drive folder and download it#\n",
    "file_list = drive.ListFile(\n",
    "    {'q': \"'1YtW460uumEGz954lHPNUsbwFnjs_tfgW' in parents\"}).GetList()\n",
    "\n",
    "# Download only files from these types from Drive folder 1sqEm5Pvxcg2X2yF2jkZKoojJmSXpysXe #\n",
    "download_Data(file_list,\".py\")\n",
    "download_Data(file_list,\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8558153f-8b86-4731-9fb4-80318067a68c",
   "metadata": {},
   "source": [
    "### Import User Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c271eeae-5596-496c-8de9-d73c695ad64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User files Imports #\n",
    "from models.customNet import CNN_custom\n",
    "from models.alexNet import CNN_AlexNet\n",
    "\n",
    "from utils.dataset_utils import cifar10_dataset_Generator, verify_data\n",
    "from utils.general_utils import get_available_devices, set_all_seeds\n",
    "from utils.matplotlib_utils import plot_figure, plot_figures_grid, plot_minibatch_loss, plot_accuracy_epochs, plot_confusion_matrix, plot_model_outputs\n",
    "from utils.models_utils import train_cnn, load_model, save_model, compute_total_accuracy, compute_confusion_matrix, get_integrated_gradient, get_occlusion, get_convolutional_layer_weights, get_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d194e5-65fd-461c-9ab7-1cc9f0f7bb25",
   "metadata": {},
   "source": [
    "## Cuda Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e48b1-3f34-4e37-bd4e-3cbc9dc4eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_available_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962f2d6-b0b7-49de-8c8c-4db7674683d9",
   "metadata": {},
   "source": [
    "### Set initial Seed for Neural Network\n",
    "Allows us to shuffle the model in the same way if we want to get the same initial weights with a Re-Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f7b4cd-bc96-4910-b612-3494a6c036ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f48966-f943-4db4-90da-e36ce615cff7",
   "metadata": {},
   "source": [
    "### Configure Dataset\n",
    "\n",
    "We need to prepare the data for the different models training, so the data is transformed using the next parameters:\n",
    "\n",
    "- Image Dimensions: Original - 32 x 32 x 3, Augmented and cropped - 64 x 64 x 3\n",
    "- Training Dataset samples - 50000\n",
    "- Validation Dataset samples - 10000\n",
    "- Test Dataset samples - 10000\n",
    "- Minibatch size - 64\n",
    "- Erasing of pixels - Probability: 0.05, Scale of Erased portion: 0.05, 0.1, Colors Erased: random\n",
    "\n",
    "Using this augmentation technics we can augmentate the number of images in the dataset, making them different than the original set. This way the networks can train without overfitting the model. In this case the data is not normalized, but the distribution of the clases inside of the dataloaders are evenly distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6315a35b-aa25-41f4-bcb3-75507ae9f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Configuration #\n",
    "MINIBATCH_SIZE = 64\n",
    "DOWNLOAD = True\n",
    "LOG = True\n",
    "\n",
    "# Dataset Transformation Tensor using CIFAR 10 Normalized standar #\n",
    "transform_cifar = T.Compose([T.ToTensor(),\n",
    "                             T.Resize((70, 70)),\n",
    "                             T.RandomCrop((64, 64)),\n",
    "                             T.RandomErasing(0.05,(0.05,0.1),value=\"random\"),\n",
    "                             ])\n",
    "\n",
    "train_data_loader, validation_data_loader, test_data_loader = cifar10_dataset_Generator(transform_cifar,MINIBATCH_SIZE,DOWNLOAD,LOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac60d1fb-012d-4a58-a5c9-9e3089ffb8e3",
   "metadata": {},
   "source": [
    "### Verification of Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ab60d-d354-4b9f-b9c2-d355da143b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_data(train_data_loader.dataset, validation_data_loader.dataset, test_data_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54555c89-91f3-4806-a47f-e08dc7d65d36",
   "metadata": {},
   "source": [
    "### Show Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c2db8d-c119-4ea7-bf82-93b5dbd288d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(train_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25fd70-2358-44a6-873f-7891be035c47",
   "metadata": {},
   "source": [
    "### Show Multiple Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012fc71e-751b-4db0-98b7-d4d8fd07574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figures_grid(train_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e7de9-d5fd-44b6-84a5-098a8c25515c",
   "metadata": {},
   "source": [
    "### AlexNet Paper Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb701fdb-624b-4295-8b50-2ec80271f7f2",
   "metadata": {},
   "source": [
    "References\n",
    "\n",
    "[1] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \"Imagenet classification with deep convolutional neural networks.\" In Advances in Neural Information Processing Systems, pp. 1097-1105. 2012.\n",
    "\n",
    "- This model has an architecture with maxpooling and dropout, with the next hyperparameters.\n",
    "- Learning Rate: 0.0001\n",
    "- Epochs: 20\n",
    "- Minibatch: 64\n",
    "- Optimizer: Adams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dc4733-4e82-4d61-b67e-9d46cfbe82d1",
   "metadata": {},
   "source": [
    "### Neural Network AlexNet Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df8749f-08cf-44df-a34e-919829b0ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters Definitions\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Model extension save\n",
    "Model_NAME = \"alexNet.pt\"\n",
    "\n",
    "# Create model using AlexNet class\n",
    "alexNet_model = CNN_AlexNet(NUM_CLASSES)\n",
    "\n",
    "# Send Device to GPU  if available\n",
    "alexNet_model.to(device)\n",
    "\n",
    "# Optimizer implementation - Adam\n",
    "optimizer = torch.optim.Adam(alexNet_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86ea16d-298a-4ef3-af13-52c730b83676",
   "metadata": {},
   "source": [
    "### Training of Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18ba4d7-3a65-4533-8ebc-ee8c69b72971",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = train_cnn(NUM_EPOCHS,alexNet_model,optimizer,device,train_data_loader,validation_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951565af-8fa8-4410-8b12-a86cc9b03b99",
   "metadata": {},
   "source": [
    "### Save Network Model in drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916fc555-acc4-4647-9b70-1e3456f86a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(alexNet_model,Model_NAME)\n",
    "save_model(optimizer, \"optimizer_\" + Model_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc0ab33-feb3-41a3-9370-052038b99850",
   "metadata": {},
   "source": [
    "### Evaluation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9639e-050b-4a89-9818-e97d346da8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_minibatch_loss(logger,\"train_loss_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90387d48-0280-453a-94a3-259bed056968",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_epochs(logger,NUM_EPOCHS,[\"train_accuracy_epoch\",\"validation_accuracy_epoch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429609d3-7e64-49a1-884a-a388b2c907e4",
   "metadata": {},
   "source": [
    "### Graphs Explanations\n",
    "\n",
    "- We can see that the loss function has an uneven behavior, but the average is an stable descending curve, meaning the model is accurately training.\n",
    "- In case of the accuracy per epoch, we can see it the training start ramping up in the first epochs and then slows down, this could be attributed to the complexity of the network for the dataset scale, also the dropout in the classification linear part is high, so it may start to saturate the model to the point it does not train anymore. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a63f2c-6d75-4fe3-a8ac-d42827f15cb5",
   "metadata": {},
   "source": [
    "### Neural Network Custom Model Implementation\n",
    "\n",
    "- This model has an architecture with maxpooling and dropout, with the next hyperparameters.\n",
    "- Learning Rate: 0.00038\n",
    "- Epochs: 20\n",
    "- Minibatch: 64\n",
    "- Optimizer: Adams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150bcdbe-26c6-463f-9581-28e3f31ec338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters Definitions\n",
    "LEARNING_RATE = 0.00038\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Model extension save\n",
    "Model_NAME = \"custom_net.pt\"\n",
    "\n",
    "# Create model using AlexNet class\n",
    "custom_model = CNN_custom(NUM_CLASSES)\n",
    "\n",
    "custom_model.to(device)\n",
    "\n",
    "# Optimizer implementation - Adam\n",
    "optimizer = torch.optim.Adam(custom_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a742d917-473c-46ff-b6f5-82761a4466c2",
   "metadata": {},
   "source": [
    "### Evaluation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca2e9a-ddef-46be-8439-838d738f849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = train_cnn(NUM_EPOCHS,custom_model,optimizer,device,train_data_loader,validation_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872eb2f8-ea8c-4116-acba-6f4cdc4e6a5f",
   "metadata": {},
   "source": [
    "### Save Network Model in drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86662dbf-a278-4560-b70e-255f8d9d698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(custom_model, Model_NAME)\n",
    "save_model(optimizer, \"optimizer_\" + Model_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8c4e7-743c-4a7a-b2db-3d118fcf5591",
   "metadata": {},
   "source": [
    "### Evaluation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34132842-b65d-4ec6-ad61-496fa3841e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_minibatch_loss(logger,\"train_loss_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666322c-386b-4106-8763-8fbd5d796d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_epochs(logger,NUM_EPOCHS,[\"train_accuracy_epoch\",\"validation_accuracy_epoch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527b64d7-c828-4c30-9693-10a122c6d030",
   "metadata": {},
   "source": [
    "### Graphs Explanations\n",
    "\n",
    "- We can see that the loss function has an uneven behavior, but the average is an stable descending curve, meaning the model is accurately training.\n",
    "- In case of the accuracy per epoch, we can see it the training start ramping up in the first epochs and then slows down, but its not overfitting to the dataset because the validation have not reached a maximum value. We can say that the objective of getting more than 70% percent of accuracy have been achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559838c-237d-453b-b33c-c1e9dafb3bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
